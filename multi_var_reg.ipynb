{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final variables: ['CRIM', 'ZN', 'INDUS', 'CHAS', 'DIS', 'RAD', 'LSTAT']\n",
      "\n",
      "Score without k-fold, train 0.6614040986850935\n",
      "\n",
      "Score without k-fold, test 0.5624711065581123\n",
      "\n",
      "Train Fold Scores:  [0.62255679 0.56031802 0.58291084 0.6616309  0.70104557]\n",
      "Train CV Score:  0.6256924244196325\n",
      "Test Fold Scores:  [0.54563004 0.41087265 0.49748181 0.32003529 0.79723598]\n",
      "Test CV Score:  0.5142511517118004\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=278 \n",
      "[CV] criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=278 \n",
      "[CV]  criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=278, score=0.8407000950752024, total=   0.6s\n",
      "[CV] criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=278 \n",
      "[CV]  criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=278, score=0.7185650951968497, total=   0.6s\n",
      "[CV] criterion=mae, learning_rate=5, loss=quantile, max_depth=1, max_features=auto, n_estimators=140 \n",
      "[CV]  criterion=mae, learning_rate=5, loss=quantile, max_depth=1, max_features=auto, n_estimators=140, score=-2.0068990127982783e+168, total=   0.2s\n",
      "[CV] criterion=mae, learning_rate=5, loss=quantile, max_depth=1, max_features=auto, n_estimators=140 \n",
      "[CV]  criterion=mae, learning_rate=5, loss=quantile, max_depth=1, max_features=auto, n_estimators=140, score=-1.1907023761394797e+166, total=   0.3s\n",
      "[CV] criterion=mae, learning_rate=5, loss=quantile, max_depth=1, max_features=auto, n_estimators=140 \n",
      "[CV]  criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=278, score=0.8010329112957875, total=   0.6s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=102 \n",
      "[CV]  criterion=mae, learning_rate=5, loss=quantile, max_depth=1, max_features=auto, n_estimators=140, score=-1.5942397164352024e+168, total=   0.2s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=102 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=102, score=0.2103146538282723, total=   0.4s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=102 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=102, score=0.4608417379218234, total=   0.4s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=huber, max_depth=7, max_features=log2, n_estimators=369 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=102, score=0.4619124437740278, total=   0.5s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=huber, max_depth=7, max_features=log2, n_estimators=369 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=huber, max_depth=7, max_features=log2, n_estimators=369, score=0.7735207635104844, total=   8.8s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=huber, max_depth=7, max_features=log2, n_estimators=369 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=huber, max_depth=7, max_features=log2, n_estimators=369, score=0.7974568376085152, total=   9.2s\n",
      "[CV] criterion=mse, learning_rate=5, loss=huber, max_depth=7, max_features=sqrt, n_estimators=293 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:365: RuntimeWarning: overflow encountered in multiply\n",
      "  (np.abs(diff[~gamma_mask]) - gamma / 2.0))\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mse, learning_rate=5, loss=huber, max_depth=7, max_features=sqrt, n_estimators=293, score=-inf, total=   5.1s\n",
      "[CV] criterion=mse, learning_rate=5, loss=huber, max_depth=7, max_features=sqrt, n_estimators=293 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=huber, max_depth=7, max_features=log2, n_estimators=369, score=0.8023297004837613, total=  11.4s\n",
      "[CV] criterion=mse, learning_rate=5, loss=huber, max_depth=7, max_features=sqrt, n_estimators=293 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:365: RuntimeWarning: overflow encountered in multiply\n",
      "  (np.abs(diff[~gamma_mask]) - gamma / 2.0))\n",
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:363: RuntimeWarning: overflow encountered in square\n",
      "  sq_loss = np.sum(0.5 * sample_weight[gamma_mask] * diff[gamma_mask] ** 2.0)\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mse, learning_rate=5, loss=huber, max_depth=7, max_features=sqrt, n_estimators=293, score=-inf, total=   8.9s\n",
      "[CV] criterion=friedman_mse, learning_rate=5, loss=ls, max_depth=1, max_features=log2, n_estimators=493 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:282: RuntimeWarning: overflow encountered in square\n",
      "  np.sum(sample_weight * ((y - pred.ravel()) ** 2.0)))\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   25.5s\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=friedman_mse, learning_rate=5, loss=ls, max_depth=1, max_features=log2, n_estimators=493, score=-inf, total=   0.4s\n",
      "[CV] criterion=friedman_mse, learning_rate=5, loss=ls, max_depth=1, max_features=log2, n_estimators=493 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:282: RuntimeWarning: overflow encountered in square\n",
      "  np.sum(sample_weight * ((y - pred.ravel()) ** 2.0)))\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=friedman_mse, learning_rate=5, loss=ls, max_depth=1, max_features=log2, n_estimators=493, score=-inf, total=   0.7s\n",
      "[CV] criterion=friedman_mse, learning_rate=5, loss=ls, max_depth=1, max_features=log2, n_estimators=493 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:282: RuntimeWarning: overflow encountered in square\n",
      "  np.sum(sample_weight * ((y - pred.ravel()) ** 2.0)))\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=friedman_mse, learning_rate=5, loss=ls, max_depth=1, max_features=log2, n_estimators=493, score=-inf, total=   0.3s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=384 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:365: RuntimeWarning: overflow encountered in multiply\n",
      "  (np.abs(diff[~gamma_mask]) - gamma / 2.0))\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mse, learning_rate=5, loss=huber, max_depth=7, max_features=sqrt, n_estimators=293, score=-inf, total=   5.7s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=384 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=384, score=0.7060131608427861, total=   1.7s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=384 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=384, score=0.7820058347232338, total=   1.9s\n",
      "[CV] criterion=mae, learning_rate=5, loss=lad, max_depth=7, max_features=auto, n_estimators=341 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=384, score=0.8135128712715812, total=   2.0s\n",
      "[CV] criterion=mae, learning_rate=5, loss=lad, max_depth=7, max_features=auto, n_estimators=341 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mae, learning_rate=5, loss=lad, max_depth=7, max_features=auto, n_estimators=341, score=-inf, total=   1.9s\n",
      "[CV] criterion=mae, learning_rate=5, loss=lad, max_depth=7, max_features=auto, n_estimators=341 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mae, learning_rate=5, loss=lad, max_depth=7, max_features=auto, n_estimators=341, score=-inf, total=   1.6s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=quantile, max_depth=9, max_features=sqrt, n_estimators=187 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mae, learning_rate=5, loss=lad, max_depth=7, max_features=auto, n_estimators=341, score=-inf, total=   1.8s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=quantile, max_depth=9, max_features=sqrt, n_estimators=187 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=quantile, max_depth=9, max_features=sqrt, n_estimators=187, score=0.5826660896060565, total=   1.2s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=quantile, max_depth=9, max_features=sqrt, n_estimators=187 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=quantile, max_depth=9, max_features=sqrt, n_estimators=187, score=0.6846026768867333, total=   2.2s\n",
      "[CV] criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=195 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=quantile, max_depth=9, max_features=sqrt, n_estimators=187, score=0.7093730422909977, total=   2.7s\n",
      "[CV] criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=195 \n",
      "[CV]  criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=195, score=0.8030061370044547, total=   2.9s\n",
      "[CV]  criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=195, score=0.6718731011014766, total=   3.6s\n",
      "[CV] criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=195 \n",
      "[CV] criterion=friedman_mse, learning_rate=5, loss=ls, max_depth=7, max_features=auto, n_estimators=472 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:282: RuntimeWarning: overflow encountered in square\n",
      "  np.sum(sample_weight * ((y - pred.ravel()) ** 2.0)))\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=friedman_mse, learning_rate=5, loss=ls, max_depth=7, max_features=auto, n_estimators=472, score=-inf, total=   0.6s\n",
      "[CV] criterion=friedman_mse, learning_rate=5, loss=ls, max_depth=7, max_features=auto, n_estimators=472 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:282: RuntimeWarning: overflow encountered in square\n",
      "  np.sum(sample_weight * ((y - pred.ravel()) ** 2.0)))\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=195, score=0.7876985325831637, total=   1.1s\n",
      "[CV] criterion=friedman_mse, learning_rate=5, loss=ls, max_depth=7, max_features=auto, n_estimators=472 \n",
      "[CV]  criterion=friedman_mse, learning_rate=5, loss=ls, max_depth=7, max_features=auto, n_estimators=472, score=-inf, total=   0.4s\n",
      "[CV] criterion=mae, learning_rate=5, loss=huber, max_depth=1, max_features=log2, n_estimators=299 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:282: RuntimeWarning: overflow encountered in square\n",
      "  np.sum(sample_weight * ((y - pred.ravel()) ** 2.0)))\n",
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:365: RuntimeWarning: overflow encountered in multiply\n",
      "  (np.abs(diff[~gamma_mask]) - gamma / 2.0))\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mae, learning_rate=5, loss=huber, max_depth=1, max_features=log2, n_estimators=299, score=-inf, total=   0.3s\n",
      "[CV] criterion=mae, learning_rate=5, loss=huber, max_depth=1, max_features=log2, n_estimators=299 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=friedman_mse, learning_rate=5, loss=ls, max_depth=7, max_features=auto, n_estimators=472, score=-inf, total=   0.4s\n",
      "[CV] criterion=mae, learning_rate=5, loss=huber, max_depth=1, max_features=log2, n_estimators=299 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:365: RuntimeWarning: overflow encountered in multiply\n",
      "  (np.abs(diff[~gamma_mask]) - gamma / 2.0))\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mae, learning_rate=5, loss=huber, max_depth=1, max_features=log2, n_estimators=299, score=-inf, total=   0.3s\n",
      "[CV] criterion=mse, learning_rate=5, loss=lad, max_depth=1, max_features=auto, n_estimators=421 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/usr/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:365: RuntimeWarning: overflow encountered in multiply\n",
      "  (np.abs(diff[~gamma_mask]) - gamma / 2.0))\n",
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mae, learning_rate=5, loss=huber, max_depth=1, max_features=log2, n_estimators=299, score=-inf, total=   0.5s\n",
      "[CV] criterion=mse, learning_rate=5, loss=lad, max_depth=1, max_features=auto, n_estimators=421 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mse, learning_rate=5, loss=lad, max_depth=1, max_features=auto, n_estimators=421, score=-inf, total=   0.4s\n",
      "[CV] criterion=mse, learning_rate=5, loss=lad, max_depth=1, max_features=auto, n_estimators=421 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mse, learning_rate=5, loss=lad, max_depth=1, max_features=auto, n_estimators=421, score=-inf, total=   0.4s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=quantile, max_depth=7, max_features=sqrt, n_estimators=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mse, learning_rate=5, loss=lad, max_depth=1, max_features=auto, n_estimators=421, score=-inf, total=   0.5s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=quantile, max_depth=7, max_features=sqrt, n_estimators=128 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=quantile, max_depth=7, max_features=sqrt, n_estimators=128, score=0.6308247230889, total=   0.7s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=quantile, max_depth=7, max_features=sqrt, n_estimators=128 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=quantile, max_depth=7, max_features=sqrt, n_estimators=128, score=0.4350641179858209, total=   0.9s\n",
      "[CV] criterion=mae, learning_rate=5, loss=lad, max_depth=1, max_features=sqrt, n_estimators=378 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mae, learning_rate=5, loss=lad, max_depth=1, max_features=sqrt, n_estimators=378, score=-inf, total=   0.3s\n",
      "[CV] criterion=mae, learning_rate=5, loss=lad, max_depth=1, max_features=sqrt, n_estimators=378 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mae, learning_rate=5, loss=lad, max_depth=1, max_features=sqrt, n_estimators=378, score=-inf, total=   0.2s\n",
      "[CV] criterion=mae, learning_rate=5, loss=lad, max_depth=1, max_features=sqrt, n_estimators=378 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mae, learning_rate=5, loss=lad, max_depth=1, max_features=sqrt, n_estimators=378, score=-inf, total=   0.2s\n",
      "[CV] criterion=friedman_mse, learning_rate=5, loss=quantile, max_depth=1, max_features=log2, n_estimators=312 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=quantile, max_depth=7, max_features=sqrt, n_estimators=128, score=0.6474112760224219, total=   0.8s\n",
      "[CV] criterion=friedman_mse, learning_rate=5, loss=quantile, max_depth=1, max_features=log2, n_estimators=312 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=friedman_mse, learning_rate=5, loss=quantile, max_depth=1, max_features=log2, n_estimators=312, score=-inf, total=   0.1s\n",
      "[CV] criterion=friedman_mse, learning_rate=5, loss=quantile, max_depth=1, max_features=log2, n_estimators=312 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=friedman_mse, learning_rate=5, loss=quantile, max_depth=1, max_features=log2, n_estimators=312, score=-inf, total=   0.2s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=180 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=friedman_mse, learning_rate=5, loss=quantile, max_depth=1, max_features=log2, n_estimators=312, score=-inf, total=   0.2s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=180 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=180, score=0.7203330882231112, total=   0.8s\n",
      "[CV] criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=180 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=180, score=0.6916690591794521, total=   1.5s\n",
      "[CV] criterion=mse, learning_rate=5, loss=quantile, max_depth=3, max_features=log2, n_estimators=190 \n",
      "[CV]  criterion=mse, learning_rate=5, loss=quantile, max_depth=3, max_features=log2, n_estimators=190, score=-9.109386275170741e+228, total=   0.2s\n",
      "[CV] criterion=mse, learning_rate=5, loss=quantile, max_depth=3, max_features=log2, n_estimators=190 \n",
      "[CV]  criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=180, score=0.7067873866298778, total=   1.2s\n",
      "[CV] criterion=mse, learning_rate=5, loss=quantile, max_depth=3, max_features=log2, n_estimators=190 \n",
      "[CV]  criterion=mse, learning_rate=5, loss=quantile, max_depth=3, max_features=log2, n_estimators=190, score=-4.399935131887343e+228, total=   0.1s\n",
      "[CV] criterion=mse, learning_rate=5, loss=lad, max_depth=9, max_features=sqrt, n_estimators=405 \n",
      "[CV]  criterion=mse, learning_rate=5, loss=quantile, max_depth=3, max_features=log2, n_estimators=190, score=-1.1741685267822112e+228, total=   0.3s\n",
      "[CV] criterion=mse, learning_rate=5, loss=lad, max_depth=9, max_features=sqrt, n_estimators=405 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mse, learning_rate=5, loss=lad, max_depth=9, max_features=sqrt, n_estimators=405, score=-inf, total=   1.9s\n",
      "[CV] criterion=mse, learning_rate=5, loss=lad, max_depth=9, max_features=sqrt, n_estimators=405 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mse, learning_rate=5, loss=lad, max_depth=9, max_features=sqrt, n_estimators=405, score=-inf, total=   2.6s\n",
      "[CV] criterion=mae, learning_rate=5, loss=quantile, max_depth=7, max_features=sqrt, n_estimators=274 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mae, learning_rate=5, loss=quantile, max_depth=7, max_features=sqrt, n_estimators=274, score=-inf, total=   0.7s\n",
      "[CV] criterion=mae, learning_rate=5, loss=quantile, max_depth=7, max_features=sqrt, n_estimators=274 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mae, learning_rate=5, loss=quantile, max_depth=7, max_features=sqrt, n_estimators=274, score=-inf, total=   1.2s\n",
      "[CV] criterion=mae, learning_rate=5, loss=quantile, max_depth=7, max_features=sqrt, n_estimators=274 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mae, learning_rate=5, loss=quantile, max_depth=7, max_features=sqrt, n_estimators=274, score=-inf, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/metrics/regression.py:538: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=mse, learning_rate=5, loss=lad, max_depth=9, max_features=sqrt, n_estimators=405, score=-inf, total=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   51.1s finished\n",
      "/usr/lib/python3.6/site-packages/sklearn/model_selection/_search.py:675: RuntimeWarning: invalid value encountered in subtract\n",
      "  array_means[:, np.newaxis]) ** 2,\n",
      "/usr/lib/python3.6/site-packages/sklearn/model_selection/_search.py:675: RuntimeWarning: overflow encountered in square\n",
      "  array_means[:, np.newaxis]) ** 2,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'criterion': 'mae', 'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 369}\n",
      "Accuracy - Train CV:  0.791102433867587\n",
      "Accuracy - Train :  0.9999624822674393\n",
      "Accuracy - Test :  0.5717709438572165\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model,feature_selection\n",
    "import statsmodels.graphics.api as smg\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor,OLSInfluence\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.diagnostic as ssd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "seed = 2017\n",
    "##### READ DATA\n",
    "\n",
    "dataframe=pd.read_csv('BostonHausing.csv')\n",
    "\n",
    "## FEATURE SELECTION WITH VIF\n",
    "###### REMOVE MULTICOLLINEARITY\n",
    "listnames = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']\n",
    "#listnames = ['CRIM', 'ZN', 'AGE', 'DIS', 'RAD', 'LSTAT']\n",
    "## calc VIF\n",
    "\n",
    "# use the list to select a subset from original DataFrame\n",
    "X = dataframe[listnames]\n",
    "Y = dataframe['MEDV']\n",
    "\n",
    "\n",
    "for i in np.arange(0,len(listnames)):\n",
    "    vif = [variance_inflation_factor(X[listnames].values, ix) for ix in range(X[listnames].shape[1])]\n",
    "    maxloc = vif.index(max(vif))\n",
    "    if max(vif) > 10:\n",
    "        #print('vif :', vif)\n",
    "        #print('dropping' + X[listnames].columns[maxloc] + 'at index: ' + str(maxloc))\n",
    "        del listnames[maxloc]\n",
    "    else:\n",
    "        break\n",
    "print('Final variables:', listnames)\n",
    "\n",
    "X = dataframe[listnames]\n",
    "Y = dataframe['MEDV']\n",
    "\n",
    "# Normalize Data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)\n",
    "# evaluate the model by splitting into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 0)\n",
    "'''\n",
    "### CREATE FITTED MODEL\n",
    "lm=sm.OLS(Y_train,X_train)\n",
    "lmf = lm.fit()\n",
    "### PRINT SUMMARY\n",
    "print(lmf.summary())  # check p-values\n",
    "'''\n",
    "\n",
    "## CREAT FITTED MODEL\n",
    "model = linear_model.LinearRegression()\n",
    "modelf=model.fit(X_train, Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print('\\nScore without k-fold, train',modelf.score(X_train, Y_train))\n",
    "print('\\nScore without k-fold, test',metrics.r2_score(Y_test,y_pred))\n",
    "\n",
    "# evaluate the model using 10-fold cross-validation\n",
    "train_scores = cross_val_score(model, X_train, Y_train, cv=5)\n",
    "test_scores = cross_val_score(model, X_test, Y_test, cv=5)\n",
    "print (\"\\nTrain Fold Scores: \", train_scores)\n",
    "print (\"Train CV Score: \", train_scores.mean())\n",
    "print (\"Test Fold Scores: \", test_scores)\n",
    "print (\"Test CV Score: \", test_scores.mean())\n",
    "'''\n",
    "# Using Bagging \n",
    "\n",
    "model_Bag = BaggingRegressor(base_estimator=model, n_estimators=70, random_state=0).fit(X_train,Y_train)\n",
    "results = model_selection.cross_val_score(model_Bag, X_train, Y_train,cv=5)\n",
    "print('~~~~~~~~~~~')\n",
    "print (\"Linear regression (Bagging) - Train : \", results.mean())\n",
    "print (\"Linear regression  (Bagging) - Test : \", metrics.r2_score(model_Bag.predict(X_test), Y_test))\n",
    "\n",
    "\n",
    "# Using RandomForestRegressor\n",
    "model_rfr=RandomForestRegressor(random_state=seed)\n",
    "model_rfr.fit(X_train,Y_train)\n",
    "results = model_selection.cross_val_score(model_rfr, X_train, Y_train,cv=5)\n",
    "print('~~~~~~~~~~~')\n",
    "print (\"Linear regression (RandomForestRegressor) - Train : \", results.mean())\n",
    "print (\"Linear regression  (RandomForestRegressor) - Test : \", metrics.r2_score(model_rfr.predict(X_test), Y_test))\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'n_estimators':sp_randint(100,1000),\n",
    "'criterion': ['mse', 'mae'],\n",
    "'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(model_rfr, param_distributions=param_dist,cv=None, n_iter=n_iter_search,\n",
    "verbose=5, n_jobs=-1, random_state=seed)\n",
    "random_search.fit(X_train, Y_train)\n",
    "# report(random_search.cv_results_)\n",
    "print ('Best Parameters: ', random_search.best_params_)\n",
    "results = model_selection.cross_val_score(random_search.best_estimator_,X_train,Y_train, cv=None)\n",
    "print (\"Accuracy - Train CV: \", results.mean())\n",
    "print (\"Accuracy - Train : \", metrics.r2_score(random_search.best_estimator_.predict(X_train), Y_train))\n",
    "print (\"Accuracy - Test : \", metrics.r2_score(random_search.best_estimator_.predict(X_test), Y_test))\n",
    "\n",
    "#Best Parameters:  {'criterion': 'mse', 'max_features': 'log2', 'n_estimators': 312}\n",
    "#Accuracy - Train CV:  0.7952687143532291\n",
    "#Accuracy - Train :  0.9737119717756719\n",
    "#Accuracy - Test :  0.4946292870977391\n",
    "\n",
    "'''\n",
    "\n",
    "# Using GradientBoostingRegressor\n",
    "model_gbr=GradientBoostingRegressor(random_state=seed)\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'n_estimators':sp_randint(100,500),\n",
    "'learning_rate': [0.1,5],\n",
    "'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "'criterion':['friedman_mse', 'mse', 'mae'],\n",
    "'max_depth': [1, 3, 5, 7, 9],\n",
    "'max_features':['auto', 'sqrt', 'log2']\n",
    "}\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(model_gbr, param_distributions=param_dist,cv=None, n_iter=n_iter_search,\n",
    "verbose=5, n_jobs=-1, random_state=seed)\n",
    "random_search.fit(X_train, Y_train)\n",
    "# report(random_search.cv_results_)\n",
    "print ('Best Parameters: ', random_search.best_params_)\n",
    "results = model_selection.cross_val_score(random_search.best_estimator_,X_train,Y_train, cv=None)\n",
    "print (\"Accuracy - Train CV: \", results.mean())\n",
    "print (\"Accuracy - Train : \", metrics.r2_score(random_search.best_estimator_.predict(X_train), Y_train))\n",
    "print (\"Accuracy - Test : \", metrics.r2_score(random_search.best_estimator_.predict(X_test), Y_test))\n",
    "\n",
    "#Best Parameters:  {'criterion': 'mae', 'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 369}\n",
    "#Accuracy - Train CV:  0.791102433867587\n",
    "#Accuracy - Train :  0.9999624822674393\n",
    "#Accuracy - Test :  0.5717709438572165\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final variables: ['CRIM', 'ZN', 'INDUS', 'CHAS', 'DIS', 'RAD', 'LSTAT']\n",
      "\n",
      "Score without k-fold, train 0.6614040986850935\n",
      "\n",
      "Score without k-fold, test 0.5624711065581123\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=30, max_features=sqrt, n_estimators=910, oob_score=False \n",
      "[CV] bootstrap=True, criterion=mae, max_depth=30, max_features=sqrt, n_estimators=910, oob_score=False \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=30, max_features=sqrt, n_estimators=910, oob_score=False, score=0.7500485958631056, total=   3.4s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=30, max_features=sqrt, n_estimators=910, oob_score=False \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=30, max_features=sqrt, n_estimators=910, oob_score=False, score=0.6864354513836836, total=   3.6s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=None, max_features=auto, n_estimators=140, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=None, max_features=auto, n_estimators=140, oob_score=False, score=0.7292057872357671, total=   1.1s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=None, max_features=auto, n_estimators=140, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=None, max_features=auto, n_estimators=140, oob_score=False, score=0.7856169673941327, total=   1.0s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=None, max_features=auto, n_estimators=140, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=None, max_features=auto, n_estimators=140, oob_score=False, score=0.8233379522445865, total=   0.7s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=5, max_features=auto, n_estimators=614, oob_score=False \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=30, max_features=sqrt, n_estimators=910, oob_score=False, score=0.7683347840005269, total=   6.3s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=5, max_features=auto, n_estimators=614, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=5, max_features=auto, n_estimators=614, oob_score=False, score=0.6676926047960534, total=   3.4s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=5, max_features=auto, n_estimators=614, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=5, max_features=auto, n_estimators=614, oob_score=False, score=0.7648116379523613, total=   4.1s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=30, max_features=sqrt, n_estimators=149, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=5, max_features=auto, n_estimators=614, oob_score=False, score=0.749241636259525, total=   4.3s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=30, max_features=sqrt, n_estimators=149, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=30, max_features=sqrt, n_estimators=149, oob_score=True, score=0.7561231882068983, total=   0.8s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=30, max_features=sqrt, n_estimators=149, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=30, max_features=sqrt, n_estimators=149, oob_score=True, score=0.6955360964625602, total=   0.5s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=5, max_features=sqrt, n_estimators=420, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=30, max_features=sqrt, n_estimators=149, oob_score=True, score=0.7994560045706852, total=   0.4s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=5, max_features=sqrt, n_estimators=420, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=5, max_features=sqrt, n_estimators=420, oob_score=True, score=0.5844815839557804, total=   8.0s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=5, max_features=sqrt, n_estimators=420, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=5, max_features=sqrt, n_estimators=420, oob_score=True, score=0.5229182869227791, total=   8.3s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=30, max_features=auto, n_estimators=608, oob_score=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   24.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=False, criterion=mae, max_depth=5, max_features=sqrt, n_estimators=420, oob_score=True, score=0.6048111210214726, total=   3.2s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=30, max_features=auto, n_estimators=608, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=30, max_features=auto, n_estimators=608, oob_score=True, score=0.7312164913555741, total=   3.1s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=30, max_features=auto, n_estimators=608, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=30, max_features=auto, n_estimators=608, oob_score=True, score=0.7904418470480665, total=   1.4s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=None, max_features=sqrt, n_estimators=756, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=30, max_features=auto, n_estimators=608, oob_score=True, score=0.8201007283838212, total=   1.4s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=None, max_features=sqrt, n_estimators=756, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=None, max_features=sqrt, n_estimators=756, oob_score=True, score=0.7610026364064448, total=   2.0s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=None, max_features=sqrt, n_estimators=756, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=None, max_features=sqrt, n_estimators=756, oob_score=True, score=0.7030752522034238, total=   2.0s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=None, max_features=log2, n_estimators=377, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=None, max_features=sqrt, n_estimators=756, oob_score=True, score=0.8015310003897709, total=   2.1s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=None, max_features=log2, n_estimators=377, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=None, max_features=log2, n_estimators=377, oob_score=True, score=0.7454402507406346, total=   1.7s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=None, max_features=log2, n_estimators=377, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=None, max_features=log2, n_estimators=377, oob_score=True, score=0.6842354566955704, total=   2.1s\n",
      "[CV] bootstrap=True, criterion=mse, max_depth=5, max_features=log2, n_estimators=922, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=None, max_features=log2, n_estimators=377, oob_score=True, score=0.7717722347065794, total=   2.2s\n",
      "[CV] bootstrap=True, criterion=mse, max_depth=5, max_features=log2, n_estimators=922, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mse, max_depth=5, max_features=log2, n_estimators=922, oob_score=True, score=0.6159844428222794, total=   4.4s\n",
      "[CV] bootstrap=True, criterion=mse, max_depth=5, max_features=log2, n_estimators=922, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mse, max_depth=5, max_features=log2, n_estimators=922, oob_score=True, score=0.5693008327563134, total=   4.5s\n",
      "[CV] bootstrap=True, criterion=mse, max_depth=5, max_features=auto, n_estimators=380, oob_score=False \n",
      "[CV]  bootstrap=True, criterion=mse, max_depth=5, max_features=auto, n_estimators=380, oob_score=False, score=0.6832844909874841, total=   0.8s\n",
      "[CV] bootstrap=True, criterion=mse, max_depth=5, max_features=auto, n_estimators=380, oob_score=False \n",
      "[CV]  bootstrap=True, criterion=mse, max_depth=5, max_features=auto, n_estimators=380, oob_score=False, score=0.7731761527635317, total=   1.2s\n",
      "[CV] bootstrap=True, criterion=mse, max_depth=5, max_features=auto, n_estimators=380, oob_score=False \n",
      "[CV]  bootstrap=True, criterion=mse, max_depth=5, max_features=log2, n_estimators=922, oob_score=True, score=0.6496377187472544, total=   2.3s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=None, max_features=sqrt, n_estimators=932, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mse, max_depth=5, max_features=auto, n_estimators=380, oob_score=False, score=0.7607517494563925, total=   1.2s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=None, max_features=sqrt, n_estimators=932, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=None, max_features=sqrt, n_estimators=932, oob_score=True, score=0.7639451970484704, total=   3.8s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=None, max_features=sqrt, n_estimators=932, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=None, max_features=sqrt, n_estimators=932, oob_score=True, score=0.7002534176580962, total=   4.2s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=30, max_features=log2, n_estimators=972, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=None, max_features=sqrt, n_estimators=932, oob_score=True, score=0.8005809496865581, total=   4.8s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=30, max_features=log2, n_estimators=972, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=30, max_features=log2, n_estimators=972, oob_score=False, score=0.76300176019097, total=   5.4s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=30, max_features=log2, n_estimators=972, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=30, max_features=log2, n_estimators=972, oob_score=False, score=0.6992513076469782, total=   3.6s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=5, max_features=auto, n_estimators=611, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=30, max_features=log2, n_estimators=972, oob_score=False, score=0.8003606130169449, total=   4.3s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=5, max_features=auto, n_estimators=611, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=5, max_features=auto, n_estimators=611, oob_score=True, score=0.66701655329952, total=   3.6s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=5, max_features=auto, n_estimators=611, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=5, max_features=auto, n_estimators=611, oob_score=True, score=0.7643461613363047, total=   2.8s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=30, max_features=auto, n_estimators=351, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=5, max_features=auto, n_estimators=611, oob_score=True, score=0.7491749459830526, total=   2.7s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=30, max_features=auto, n_estimators=351, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=30, max_features=auto, n_estimators=351, oob_score=True, score=0.7252727427919646, total=   2.3s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=30, max_features=auto, n_estimators=351, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=30, max_features=auto, n_estimators=351, oob_score=True, score=0.8089321905559529, total=   2.2s\n",
      "[CV] bootstrap=True, criterion=mse, max_depth=30, max_features=auto, n_estimators=128, oob_score=False \n",
      "[CV]  bootstrap=True, criterion=mse, max_depth=30, max_features=auto, n_estimators=128, oob_score=False, score=0.7243528338832836, total=   0.5s\n",
      "[CV] bootstrap=True, criterion=mse, max_depth=30, max_features=auto, n_estimators=128, oob_score=False \n",
      "[CV]  bootstrap=True, criterion=mse, max_depth=30, max_features=auto, n_estimators=128, oob_score=False, score=0.7799653658461104, total=   1.4s\n",
      "[CV] bootstrap=True, criterion=mse, max_depth=30, max_features=auto, n_estimators=128, oob_score=False \n",
      "[CV]  bootstrap=True, criterion=mse, max_depth=30, max_features=auto, n_estimators=128, oob_score=False, score=0.8249138386553572, total=   0.7s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=30, max_features=auto, n_estimators=591, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=30, max_features=auto, n_estimators=351, oob_score=True, score=0.8152051876104526, total=   3.4s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=30, max_features=auto, n_estimators=591, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=30, max_features=auto, n_estimators=591, oob_score=True, score=0.7252779475919231, total=   4.9s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=30, max_features=auto, n_estimators=591, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=30, max_features=auto, n_estimators=591, oob_score=True, score=0.8072304298442241, total=   5.0s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=None, max_features=sqrt, n_estimators=575, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=None, max_features=sqrt, n_estimators=575, oob_score=False, score=0.7537101037422381, total=   4.0s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=None, max_features=sqrt, n_estimators=575, oob_score=False \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=30, max_features=auto, n_estimators=591, oob_score=True, score=0.8143337970709861, total=   5.7s\n",
      "[CV] bootstrap=False, criterion=mae, max_depth=None, max_features=sqrt, n_estimators=575, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=None, max_features=sqrt, n_estimators=575, oob_score=False, score=0.6854604061368884, total=   7.3s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=30, max_features=log2, n_estimators=541, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mae, max_depth=None, max_features=sqrt, n_estimators=575, oob_score=False, score=0.7683537591579812, total=   6.1s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=30, max_features=log2, n_estimators=541, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=30, max_features=log2, n_estimators=541, oob_score=False, score=0.7636710099169602, total=   1.7s\n",
      "[CV] bootstrap=False, criterion=mse, max_depth=30, max_features=log2, n_estimators=541, oob_score=False \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=30, max_features=log2, n_estimators=541, oob_score=False, score=0.7105375230091899, total=   2.8s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=None, max_features=auto, n_estimators=461, oob_score=True \n",
      "[CV]  bootstrap=False, criterion=mse, max_depth=30, max_features=log2, n_estimators=541, oob_score=False, score=0.8007370174547237, total=   2.6s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=None, max_features=auto, n_estimators=461, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=None, max_features=auto, n_estimators=461, oob_score=True, score=0.7259223971330798, total=   2.6s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=None, max_features=auto, n_estimators=461, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=None, max_features=auto, n_estimators=461, oob_score=True, score=0.8102812706273971, total=   2.7s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=30, max_features=log2, n_estimators=117, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=30, max_features=log2, n_estimators=117, oob_score=True, score=0.7408896560922279, total=   0.4s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=30, max_features=log2, n_estimators=117, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=30, max_features=log2, n_estimators=117, oob_score=True, score=0.6863440031902361, total=   0.4s\n",
      "[CV] bootstrap=True, criterion=mae, max_depth=30, max_features=log2, n_estimators=117, oob_score=True \n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=30, max_features=log2, n_estimators=117, oob_score=True, score=0.769573438848705, total=   0.4s\n",
      "[CV]  bootstrap=True, criterion=mae, max_depth=None, max_features=auto, n_estimators=461, oob_score=True, score=0.8154474756975871, total=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'bootstrap': 'True', 'criterion': 'mae', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 461, 'oob_score': 'True'}\n",
      "Accuracy - Train CV:  0.7838837144860213\n",
      "Accuracy - Train :  0.9692502753490986\n",
      "Accuracy - Test :  0.5669731711564234\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model,feature_selection\n",
    "import statsmodels.graphics.api as smg\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor,OLSInfluence\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.diagnostic as ssd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "seed = 2017\n",
    "##### READ DATA\n",
    "\n",
    "dataframe=pd.read_csv('BostonHausing.csv')\n",
    "\n",
    "## FEATURE SELECTION WITH VIF\n",
    "###### REMOVE MULTICOLLINEARITY\n",
    "listnames = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']\n",
    "#listnames = ['CRIM', 'ZN', 'AGE', 'DIS', 'RAD', 'LSTAT']\n",
    "## calc VIF\n",
    "\n",
    "# use the list to select a subset from original DataFrame\n",
    "X = dataframe[listnames]\n",
    "Y = dataframe['MEDV']\n",
    "\n",
    "\n",
    "for i in np.arange(0,len(listnames)):\n",
    "    vif = [variance_inflation_factor(X[listnames].values, ix) for ix in range(X[listnames].shape[1])]\n",
    "    maxloc = vif.index(max(vif))\n",
    "    if max(vif) > 10:\n",
    "        #print('vif :', vif)\n",
    "        #print('dropping' + X[listnames].columns[maxloc] + 'at index: ' + str(maxloc))\n",
    "        del listnames[maxloc]\n",
    "    else:\n",
    "        break\n",
    "print('Final variables:', listnames)\n",
    "\n",
    "X = dataframe[listnames]\n",
    "Y = dataframe['MEDV']\n",
    "\n",
    "# Normalize Data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)\n",
    "# evaluate the model by splitting into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 0)\n",
    "'''\n",
    "### CREATE FITTED MODEL\n",
    "lm=sm.OLS(Y_train,X_train)\n",
    "lmf = lm.fit()\n",
    "### PRINT SUMMARY\n",
    "print(lmf.summary())  # check p-values\n",
    "'''\n",
    "\n",
    "## CREAT FITTED MODEL\n",
    "model = linear_model.LinearRegression()\n",
    "modelf=model.fit(X_train, Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print('\\nScore without k-fold, train',modelf.score(X_train, Y_train))\n",
    "print('\\nScore without k-fold, test',metrics.r2_score(Y_test,y_pred))\n",
    "\n",
    "# Using ExtraTreesRegressor\n",
    "model_gbr=ExtraTreesRegressor(random_state=seed)\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'n_estimators':sp_randint(100,1000),\n",
    "'criterion': ['mse', 'mae'],\n",
    "'max_features': ['auto', 'sqrt', 'log2'],\n",
    "'max_depth':[None,5,30],\n",
    "'bootstrap':['False','True'],\n",
    "'oob_score':['False','True']\n",
    "}\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(model_gbr, param_distributions=param_dist,cv=None, n_iter=n_iter_search,\n",
    "verbose=5, n_jobs=-1, random_state=seed)\n",
    "random_search.fit(X_train, Y_train)\n",
    "# report(random_search.cv_results_)\n",
    "print ('Best Parameters: ', random_search.best_params_)\n",
    "results = model_selection.cross_val_score(random_search.best_estimator_,X_train,Y_train, cv=None)\n",
    "print (\"Accuracy - Train CV: \", results.mean())\n",
    "print (\"Accuracy - Train : \", metrics.r2_score(random_search.best_estimator_.predict(X_train), Y_train))\n",
    "print (\"Accuracy - Test : \", metrics.r2_score(random_search.best_estimator_.predict(X_test), Y_test))\n",
    "\n",
    "#Best Parameters:  {'bootstrap': 'True', 'criterion': 'mae', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 461, 'oob_score': 'True'}\n",
    "#Accuracy - Train CV:  0.7838837144860213\n",
    "#Accuracy - Train :  0.9692502753490986\n",
    "#Accuracy - Test :  0.5669731711564234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final variables: ['CRIM', 'ZN', 'INDUS', 'CHAS', 'DIS', 'RAD', 'LSTAT']\n",
      "\n",
      "Score without k-fold, train 0.6614040986850935\n",
      "\n",
      "Score without k-fold, test 0.5624711065581123\n",
      "\n",
      "Train Fold Scores:  [0.62255679 0.56031802 0.58291084 0.6616309  0.70104557]\n",
      "Train CV Score:  0.6256924244196325\n",
      "Test Fold Scores:  [0.54563004 0.41087265 0.49748181 0.32003529 0.79723598]\n",
      "Test CV Score:  0.5142511517118004\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] learning_rate=10, loss=exponential, n_estimators=191 ............\n",
      "[CV] learning_rate=10, loss=exponential, n_estimators=191 ............\n",
      "[CV]  learning_rate=10, loss=exponential, n_estimators=191, score=0.12178044529654208, total=   0.3s\n",
      "[CV] learning_rate=10, loss=exponential, n_estimators=191 ............\n",
      "[CV]  learning_rate=10, loss=exponential, n_estimators=191, score=0.07938924206802522, total=   0.4s\n",
      "[CV] learning_rate=11, loss=linear, n_estimators=228 .................\n",
      "[CV]  learning_rate=10, loss=exponential, n_estimators=191, score=-0.00866211649329962, total=   0.4s\n",
      "[CV] learning_rate=11, loss=linear, n_estimators=228 .................\n",
      "[CV]  learning_rate=11, loss=linear, n_estimators=228, score=-2.8400661105155116, total=   0.5s\n",
      "[CV] learning_rate=11, loss=linear, n_estimators=228 .................\n",
      "[CV]  learning_rate=11, loss=linear, n_estimators=228, score=-5.521051235387736, total=   1.2s\n",
      "[CV] learning_rate=4, loss=linear, n_estimators=50 ...................\n",
      "[CV]  learning_rate=4, loss=linear, n_estimators=50, score=0.5440426596049601, total=   0.0s\n",
      "[CV] learning_rate=4, loss=linear, n_estimators=50 ...................\n",
      "[CV]  learning_rate=4, loss=linear, n_estimators=50, score=0.4638845356481592, total=   0.1s\n",
      "[CV] learning_rate=4, loss=linear, n_estimators=50 ...................\n",
      "[CV]  learning_rate=4, loss=linear, n_estimators=50, score=0.4929971963373072, total=   0.1s\n",
      "[CV] learning_rate=9, loss=exponential, n_estimators=262 .............\n",
      "[CV]  learning_rate=11, loss=linear, n_estimators=228, score=-3.1453639265262074, total=   1.7s\n",
      "[CV] learning_rate=9, loss=exponential, n_estimators=262 .............\n",
      "[CV]  learning_rate=9, loss=exponential, n_estimators=262, score=0.09026211923727268, total=   1.4s\n",
      "[CV] learning_rate=9, loss=exponential, n_estimators=262 .............\n",
      "[CV]  learning_rate=9, loss=exponential, n_estimators=262, score=0.11946694996955366, total=   1.9s\n",
      "[CV] learning_rate=10, loss=linear, n_estimators=52 ..................\n",
      "[CV]  learning_rate=10, loss=linear, n_estimators=52, score=-6.854044452250002, total=   0.2s\n",
      "[CV] learning_rate=10, loss=linear, n_estimators=52 ..................\n",
      "[CV]  learning_rate=9, loss=exponential, n_estimators=262, score=0.1261964826265599, total=   1.5s\n",
      "[CV]  learning_rate=10, loss=linear, n_estimators=52, score=-2.927992683806318, total=   0.3s\n",
      "[CV] learning_rate=5, loss=exponential, n_estimators=85 ..............\n",
      "[CV] learning_rate=10, loss=linear, n_estimators=52 ..................\n",
      "[CV]  learning_rate=5, loss=exponential, n_estimators=85, score=0.32490960016850573, total=   0.0s\n",
      "[CV] learning_rate=5, loss=exponential, n_estimators=85 ..............\n",
      "[CV]  learning_rate=5, loss=exponential, n_estimators=85, score=0.5090769517088171, total=   0.0s\n",
      "[CV] learning_rate=5, loss=exponential, n_estimators=85 ..............\n",
      "[CV]  learning_rate=10, loss=linear, n_estimators=52, score=-7.829665819021674, total=   0.1s\n",
      "[CV] learning_rate=14, loss=square, n_estimators=388 .................\n",
      "[CV]  learning_rate=5, loss=exponential, n_estimators=85, score=0.6683701344253865, total=   0.0s\n",
      "[CV] learning_rate=14, loss=square, n_estimators=388 .................\n",
      "[CV]  learning_rate=14, loss=square, n_estimators=388, score=-3.694854670430627, total=   0.0s\n",
      "[CV] learning_rate=14, loss=square, n_estimators=388 .................\n",
      "[CV]  learning_rate=14, loss=square, n_estimators=388, score=-3.2499503974674147, total=   0.0s\n",
      "[CV]  learning_rate=14, loss=square, n_estimators=388, score=-12.349504330754462, total=   0.0s\n",
      "[CV] learning_rate=4, loss=square, n_estimators=243 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    5.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] learning_rate=4, loss=square, n_estimators=243 ..................\n",
      "[CV]  learning_rate=4, loss=square, n_estimators=243, score=-12.349504330754462, total=   0.1s\n",
      "[CV] learning_rate=4, loss=square, n_estimators=243 ..................\n",
      "[CV]  learning_rate=4, loss=square, n_estimators=243, score=-3.694854670430627, total=   0.1s\n",
      "[CV] learning_rate=1, loss=linear, n_estimators=242 ..................\n",
      "[CV]  learning_rate=1, loss=linear, n_estimators=242, score=0.5428755839452278, total=   0.0s\n",
      "[CV] learning_rate=1, loss=linear, n_estimators=242 ..................\n",
      "[CV]  learning_rate=1, loss=linear, n_estimators=242, score=0.5527756639026871, total=   0.0s\n",
      "[CV] learning_rate=1, loss=linear, n_estimators=242 ..................\n",
      "[CV]  learning_rate=1, loss=linear, n_estimators=242, score=0.6870985328492785, total=   0.0s\n",
      "[CV] learning_rate=10, loss=exponential, n_estimators=342 ............\n",
      "[CV]  learning_rate=4, loss=square, n_estimators=243, score=-3.2499503974674147, total=   0.6s\n",
      "[CV] learning_rate=10, loss=exponential, n_estimators=342 ............\n",
      "[CV]  learning_rate=10, loss=exponential, n_estimators=342, score=-0.11001160273606736, total=   0.5s\n",
      "[CV] learning_rate=10, loss=exponential, n_estimators=342 ............\n",
      "[CV]  learning_rate=10, loss=exponential, n_estimators=342, score=-1.6461326722738976, total=   0.5s\n",
      "[CV] learning_rate=1, loss=square, n_estimators=194 ..................\n",
      "[CV]  learning_rate=1, loss=square, n_estimators=194, score=0.43566146251934434, total=   0.0s\n",
      "[CV] learning_rate=1, loss=square, n_estimators=194 ..................\n",
      "[CV]  learning_rate=1, loss=square, n_estimators=194, score=0.5281401071348992, total=   0.0s\n",
      "[CV] learning_rate=1, loss=square, n_estimators=194 ..................\n",
      "[CV]  learning_rate=1, loss=square, n_estimators=194, score=0.6680324856719728, total=   0.0s\n",
      "[CV] learning_rate=11, loss=square, n_estimators=115 .................\n",
      "[CV]  learning_rate=11, loss=square, n_estimators=115, score=-2.8400661105155116, total=   0.0s\n",
      "[CV] learning_rate=11, loss=square, n_estimators=115 .................\n",
      "[CV]  learning_rate=11, loss=square, n_estimators=115, score=-7.42506274670734, total=   0.0s\n",
      "[CV] learning_rate=11, loss=square, n_estimators=115 .................\n",
      "[CV]  learning_rate=11, loss=square, n_estimators=115, score=-7.829665819021674, total=   0.0s\n",
      "[CV] learning_rate=18, loss=exponential, n_estimators=360 ............\n",
      "[CV]  learning_rate=18, loss=exponential, n_estimators=360, score=-1.0676768893320214, total=   0.0s\n",
      "[CV] learning_rate=18, loss=exponential, n_estimators=360 ............\n",
      "[CV]  learning_rate=18, loss=exponential, n_estimators=360, score=-6.493001233199551, total=   0.0s\n",
      "[CV] learning_rate=18, loss=exponential, n_estimators=360 ............\n",
      "[CV]  learning_rate=10, loss=exponential, n_estimators=342, score=0.2921613103765742, total=   0.6s\n",
      "[CV] learning_rate=16, loss=square, n_estimators=137 .................\n",
      "[CV]  learning_rate=16, loss=square, n_estimators=137, score=-4.544286980974804, total=   0.0s\n",
      "[CV] learning_rate=16, loss=square, n_estimators=137 .................\n",
      "[CV]  learning_rate=16, loss=square, n_estimators=137, score=-3.694854670430627, total=   0.0s\n",
      "[CV] learning_rate=16, loss=square, n_estimators=137 .................\n",
      "[CV]  learning_rate=18, loss=exponential, n_estimators=360, score=0.2657066561503898, total=   0.0s\n",
      "[CV] learning_rate=1, loss=linear, n_estimators=184 ..................\n",
      "[CV]  learning_rate=16, loss=square, n_estimators=137, score=-7.829665819021674, total=   0.0s\n",
      "[CV] learning_rate=1, loss=linear, n_estimators=184 ..................\n",
      "[CV]  learning_rate=1, loss=linear, n_estimators=184, score=0.5315640250132294, total=   0.0s\n",
      "[CV] learning_rate=1, loss=linear, n_estimators=184 ..................\n",
      "[CV]  learning_rate=1, loss=linear, n_estimators=184, score=0.5755647462561115, total=   0.0s\n",
      "[CV] learning_rate=11, loss=exponential, n_estimators=145 ............\n",
      "[CV]  learning_rate=1, loss=linear, n_estimators=184, score=0.6914567367084112, total=   0.0s\n",
      "[CV] learning_rate=11, loss=exponential, n_estimators=145 ............\n",
      "[CV]  learning_rate=11, loss=exponential, n_estimators=145, score=0.07292383337210384, total=   0.2s\n",
      "[CV] learning_rate=11, loss=exponential, n_estimators=145 ............\n",
      "[CV]  learning_rate=11, loss=exponential, n_estimators=145, score=-0.16347542343123544, total=   0.3s\n",
      "[CV] learning_rate=4, loss=linear, n_estimators=371 ..................\n",
      "[CV]  learning_rate=4, loss=linear, n_estimators=371, score=0.5441331346118023, total=   0.0s\n",
      "[CV] learning_rate=4, loss=linear, n_estimators=371 ..................\n",
      "[CV]  learning_rate=4, loss=linear, n_estimators=371, score=0.42913565277773263, total=   0.0s\n",
      "[CV] learning_rate=4, loss=linear, n_estimators=371 ..................\n",
      "[CV]  learning_rate=4, loss=linear, n_estimators=371, score=0.5091150605505395, total=   0.0s\n",
      "[CV] learning_rate=1, loss=linear, n_estimators=422 ..................\n",
      "[CV]  learning_rate=1, loss=linear, n_estimators=422, score=0.5010108289694267, total=   0.0s\n",
      "[CV] learning_rate=1, loss=linear, n_estimators=422 ..................\n",
      "[CV]  learning_rate=1, loss=linear, n_estimators=422, score=0.5722530127879952, total=   0.0s\n",
      "[CV] learning_rate=1, loss=linear, n_estimators=422 ..................\n",
      "[CV]  learning_rate=1, loss=linear, n_estimators=422, score=0.692676525377989, total=   0.1s\n",
      "[CV] learning_rate=4, loss=exponential, n_estimators=241 .............\n",
      "[CV]  learning_rate=4, loss=exponential, n_estimators=241, score=0.2917868204170574, total=   0.0s\n",
      "[CV] learning_rate=4, loss=exponential, n_estimators=241 .............\n",
      "[CV]  learning_rate=4, loss=exponential, n_estimators=241, score=0.49826416961713993, total=   0.1s\n",
      "[CV] learning_rate=4, loss=exponential, n_estimators=241 .............\n",
      "[CV]  learning_rate=11, loss=exponential, n_estimators=145, score=-0.2349111873359242, total=   0.5s\n",
      "[CV] learning_rate=3, loss=linear, n_estimators=132 ..................\n",
      "[CV]  learning_rate=3, loss=linear, n_estimators=132, score=0.5887219751779346, total=   0.0s\n",
      "[CV]  learning_rate=4, loss=exponential, n_estimators=241, score=0.5449318333035846, total=   0.0s\n",
      "[CV] learning_rate=3, loss=linear, n_estimators=132 ..................\n",
      "[CV] learning_rate=3, loss=linear, n_estimators=132 ..................\n",
      "[CV]  learning_rate=3, loss=linear, n_estimators=132, score=0.6587756513827513, total=   0.0s\n",
      "[CV]  learning_rate=3, loss=linear, n_estimators=132, score=0.5135889718837665, total=   0.0s\n",
      "Best Parameters:  {'learning_rate': 1, 'loss': 'linear', 'n_estimators': 184}\n",
      "Accuracy - Train CV:  0.5934515729681066\n",
      "Accuracy - Train :  0.49911852143960267\n",
      "Accuracy - Test :  0.3572295579715925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    8.1s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model,feature_selection\n",
    "import statsmodels.graphics.api as smg\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor,OLSInfluence\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.diagnostic as ssd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "seed = 2017\n",
    "##### READ DATA\n",
    "\n",
    "dataframe=pd.read_csv('BostonHausing.csv')\n",
    "\n",
    "## FEATURE SELECTION WITH VIF\n",
    "###### REMOVE MULTICOLLINEARITY\n",
    "listnames = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']\n",
    "#listnames = ['CRIM', 'ZN', 'AGE', 'DIS', 'RAD', 'LSTAT']\n",
    "## calc VIF\n",
    "\n",
    "# use the list to select a subset from original DataFrame\n",
    "X = dataframe[listnames]\n",
    "Y = dataframe['MEDV']\n",
    "\n",
    "\n",
    "for i in np.arange(0,len(listnames)):\n",
    "    vif = [variance_inflation_factor(X[listnames].values, ix) for ix in range(X[listnames].shape[1])]\n",
    "    maxloc = vif.index(max(vif))\n",
    "    if max(vif) > 10:\n",
    "        #print('vif :', vif)\n",
    "        #print('dropping' + X[listnames].columns[maxloc] + 'at index: ' + str(maxloc))\n",
    "        del listnames[maxloc]\n",
    "    else:\n",
    "        break\n",
    "print('Final variables:', listnames)\n",
    "\n",
    "X = dataframe[listnames]\n",
    "Y = dataframe['MEDV']\n",
    "\n",
    "# Normalize Data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)\n",
    "# evaluate the model by splitting into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 0)\n",
    "'''\n",
    "### CREATE FITTED MODEL\n",
    "lm=sm.OLS(Y_train,X_train)\n",
    "lmf = lm.fit()\n",
    "### PRINT SUMMARY\n",
    "print(lmf.summary())  # check p-values\n",
    "'''\n",
    "\n",
    "## CREAT FITTED MODEL\n",
    "model = linear_model.LinearRegression()\n",
    "modelf=model.fit(X_train, Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print('\\nScore without k-fold, train',modelf.score(X_train, Y_train))\n",
    "print('\\nScore without k-fold, test',metrics.r2_score(Y_test,y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# evaluate the model using 10-fold cross-validation\n",
    "train_scores = cross_val_score(model, X_train, Y_train, cv=5)\n",
    "test_scores = cross_val_score(model, X_test, Y_test, cv=5)\n",
    "print (\"\\nTrain Fold Scores: \", train_scores)\n",
    "print (\"Train CV Score: \", train_scores.mean())\n",
    "print (\"Test Fold Scores: \", test_scores)\n",
    "print (\"Test CV Score: \", test_scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "# Using AdaBoostRegressor\n",
    "model_abr=AdaBoostRegressor(base_estimator=model)\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'n_estimators':sp_randint(50,500),\n",
    "'learning_rate': sp_randint(1,20),\n",
    "'loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(model_abr, param_distributions=param_dist,cv=None, n_iter=n_iter_search,\n",
    "verbose=5, n_jobs=-1, random_state=seed)\n",
    "random_search.fit(X_train, Y_train)\n",
    "# report(random_search.cv_results_)\n",
    "print ('Best Parameters: ', random_search.best_params_)\n",
    "results = model_selection.cross_val_score(random_search.best_estimator_,X_train,Y_train, cv=None)\n",
    "print (\"Accuracy - Train CV: \", results.mean())\n",
    "print (\"Accuracy - Train : \", metrics.r2_score(random_search.best_estimator_.predict(X_train), Y_train))\n",
    "print (\"Accuracy - Test : \", metrics.r2_score(random_search.best_estimator_.predict(X_test), Y_test))\n",
    "\n",
    "#Best Parameters:  {'learning_rate': 1, 'loss': 'linear', 'n_estimators': 184}\n",
    "#Accuracy - Train CV:  0.5934515729681066\n",
    "#Accuracy - Train :  0.49911852143960267\n",
    "#Accuracy - Test :  0.3572295579715925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
